{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LfBLhvmX-LyW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecb318c5-ab42-40b1-d5f7-173715dbad6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download adarshsng/googlenewsvectors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-Iuka3FFmoW",
        "outputId": "7a97adc8-cce0-4cb2-a2d0-759ff0806561"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/adarshsng/googlenewsvectors\n",
            "License(s): unknown\n",
            "Downloading googlenewsvectors.zip to /content\n",
            " 99% 1.63G/1.64G [00:18<00:00, 154MB/s]\n",
            "100% 1.64G/1.64G [00:18<00:00, 92.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "zip_path = \"googlenewsvectors.zip\"\n",
        "extract_path = \"./\"  # Directory where it will be extracted\n",
        "\n",
        "# Extract the ZIP file\n",
        "with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(\"Unzipping completed!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSGr3NXfGSjb",
        "outputId": "29acc3bf-830b-4673-9ce9-bf9194698f32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unzipping completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "\n",
        "# Load the pretrained Word2Vec model (in binary format)\n",
        "model_path = 'GoogleNews-vectors-negative300.bin'  # Replace with the actual path to the Word2Vec model file\n",
        "model = gensim.models.KeyedVectors.load_word2vec_format(model_path, binary=True)\n",
        "\n",
        "# Check if the model is loaded properly\n",
        "print(\"Model loaded successfully!\")\n",
        "\n",
        "# Example of finding the most similar words to a given word\n",
        "word = \"king\"\n",
        "print(f\"\\nMost similar words to '{word}':\")\n",
        "similar_words = model.most_similar(word, topn=10)\n",
        "for similar_word, similarity in similar_words:\n",
        "    print(f\"{similar_word}: {similarity}\")\n",
        "\n",
        "# Example of word analogy: \"king is to queen as man is to woman\"\n",
        "print(\"\\nWord analogy: king - man + woman = ?\")\n",
        "result = model.most_similar(positive=[\"king\", \"woman\"], negative=[\"man\"], topn=1)\n",
        "print(f\"Answer: {result[0][0]} with similarity {result[0][1]}\")\n",
        "\n",
        "# Example of finding word similarity\n",
        "word1, word2 = \"king\", \"queen\"\n",
        "similarity = model.similarity(word1, word2)\n",
        "print(f\"\\nCosine similarity between '{word1}' and '{word2}': {similarity}\")\n",
        "\n",
        "# Example of finding the vector representation of a word\n",
        "word_vector = model['king']\n",
        "\n",
        "print(f\"\\nVector representation of the word 'king':\\n{word_vector}\")\n",
        "\n",
        "# Example of finding words that don't match in a set of words (odd one out)\n",
        "odd_one_out = model.doesnt_match([\"man\", \"woman\", \"king\", \"apple\"])\n",
        "print(f\"\\nOdd one out in the set ['man', 'woman', 'king', 'apple']: {odd_one_out}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIF1rhYW-TCx",
        "outputId": "80b9a1fb-9b5d-4a47-fe95-1532a6a1c315"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully!\n",
            "\n",
            "Most similar words to 'king':\n",
            "kings: 0.7138045430183411\n",
            "queen: 0.6510956883430481\n",
            "monarch: 0.6413194537162781\n",
            "crown_prince: 0.6204220056533813\n",
            "prince: 0.6159993410110474\n",
            "sultan: 0.5864824056625366\n",
            "ruler: 0.5797567367553711\n",
            "princes: 0.5646552443504333\n",
            "Prince_Paras: 0.5432944297790527\n",
            "throne: 0.5422105193138123\n",
            "\n",
            "Word analogy: king - man + woman = ?\n",
            "Answer: queen with similarity 0.7118193507194519\n",
            "\n",
            "Cosine similarity between 'king' and 'queen': 0.6510956883430481\n",
            "\n",
            "Vector representation of the word 'king':\n",
            "[ 1.25976562e-01  2.97851562e-02  8.60595703e-03  1.39648438e-01\n",
            " -2.56347656e-02 -3.61328125e-02  1.11816406e-01 -1.98242188e-01\n",
            "  5.12695312e-02  3.63281250e-01 -2.42187500e-01 -3.02734375e-01\n",
            " -1.77734375e-01 -2.49023438e-02 -1.67968750e-01 -1.69921875e-01\n",
            "  3.46679688e-02  5.21850586e-03  4.63867188e-02  1.28906250e-01\n",
            "  1.36718750e-01  1.12792969e-01  5.95703125e-02  1.36718750e-01\n",
            "  1.01074219e-01 -1.76757812e-01 -2.51953125e-01  5.98144531e-02\n",
            "  3.41796875e-01 -3.11279297e-02  1.04492188e-01  6.17675781e-02\n",
            "  1.24511719e-01  4.00390625e-01 -3.22265625e-01  8.39843750e-02\n",
            "  3.90625000e-02  5.85937500e-03  7.03125000e-02  1.72851562e-01\n",
            "  1.38671875e-01 -2.31445312e-01  2.83203125e-01  1.42578125e-01\n",
            "  3.41796875e-01 -2.39257812e-02 -1.09863281e-01  3.32031250e-02\n",
            " -5.46875000e-02  1.53198242e-02 -1.62109375e-01  1.58203125e-01\n",
            " -2.59765625e-01  2.01416016e-02 -1.63085938e-01  1.35803223e-03\n",
            " -1.44531250e-01 -5.68847656e-02  4.29687500e-02 -2.46582031e-02\n",
            "  1.85546875e-01  4.47265625e-01  9.58251953e-03  1.31835938e-01\n",
            "  9.86328125e-02 -1.85546875e-01 -1.00097656e-01 -1.33789062e-01\n",
            " -1.25000000e-01  2.83203125e-01  1.23046875e-01  5.32226562e-02\n",
            " -1.77734375e-01  8.59375000e-02 -2.18505859e-02  2.05078125e-02\n",
            " -1.39648438e-01  2.51464844e-02  1.38671875e-01 -1.05468750e-01\n",
            "  1.38671875e-01  8.88671875e-02 -7.51953125e-02 -2.13623047e-02\n",
            "  1.72851562e-01  4.63867188e-02 -2.65625000e-01  8.91113281e-03\n",
            "  1.49414062e-01  3.78417969e-02  2.38281250e-01 -1.24511719e-01\n",
            " -2.17773438e-01 -1.81640625e-01  2.97851562e-02  5.71289062e-02\n",
            " -2.89306641e-02  1.24511719e-02  9.66796875e-02 -2.31445312e-01\n",
            "  5.81054688e-02  6.68945312e-02  7.08007812e-02 -3.08593750e-01\n",
            " -2.14843750e-01  1.45507812e-01 -4.27734375e-01 -9.39941406e-03\n",
            "  1.54296875e-01 -7.66601562e-02  2.89062500e-01  2.77343750e-01\n",
            " -4.86373901e-04 -1.36718750e-01  3.24218750e-01 -2.46093750e-01\n",
            " -3.03649902e-03 -2.11914062e-01  1.25000000e-01  2.69531250e-01\n",
            "  2.04101562e-01  8.25195312e-02 -2.01171875e-01 -1.60156250e-01\n",
            " -3.78417969e-02 -1.20117188e-01  1.15234375e-01 -4.10156250e-02\n",
            " -3.95507812e-02 -8.98437500e-02  6.34765625e-03  2.03125000e-01\n",
            "  1.86523438e-01  2.73437500e-01  6.29882812e-02  1.41601562e-01\n",
            " -9.81445312e-02  1.38671875e-01  1.82617188e-01  1.73828125e-01\n",
            "  1.73828125e-01 -2.37304688e-01  1.78710938e-01  6.34765625e-02\n",
            "  2.36328125e-01 -2.08984375e-01  8.74023438e-02 -1.66015625e-01\n",
            " -7.91015625e-02  2.43164062e-01 -8.88671875e-02  1.26953125e-01\n",
            " -2.16796875e-01 -1.73828125e-01 -3.59375000e-01 -8.25195312e-02\n",
            " -6.49414062e-02  5.07812500e-02  1.35742188e-01 -7.47070312e-02\n",
            " -1.64062500e-01  1.15356445e-02  4.45312500e-01 -2.15820312e-01\n",
            " -1.11328125e-01 -1.92382812e-01  1.70898438e-01 -1.25000000e-01\n",
            "  2.65502930e-03  1.92382812e-01 -1.74804688e-01  1.39648438e-01\n",
            "  2.92968750e-01  1.13281250e-01  5.95703125e-02 -6.39648438e-02\n",
            "  9.96093750e-02 -2.72216797e-02  1.96533203e-02  4.27246094e-02\n",
            " -2.46093750e-01  6.39648438e-02 -2.25585938e-01 -1.68945312e-01\n",
            "  2.89916992e-03  8.20312500e-02  3.41796875e-01  4.32128906e-02\n",
            "  1.32812500e-01  1.42578125e-01  7.61718750e-02  5.98144531e-02\n",
            " -1.19140625e-01  2.74658203e-03 -6.29882812e-02 -2.72216797e-02\n",
            " -4.82177734e-03 -8.20312500e-02 -2.49023438e-02 -4.00390625e-01\n",
            " -1.06933594e-01  4.24804688e-02  7.76367188e-02 -1.16699219e-01\n",
            "  7.37304688e-02 -9.22851562e-02  1.07910156e-01  1.58203125e-01\n",
            "  4.24804688e-02  1.26953125e-01  3.61328125e-02  2.67578125e-01\n",
            " -1.01074219e-01 -3.02734375e-01 -5.76171875e-02  5.05371094e-02\n",
            "  5.26428223e-04 -2.07031250e-01 -1.38671875e-01 -8.97216797e-03\n",
            " -2.78320312e-02 -1.41601562e-01  2.07031250e-01 -1.58203125e-01\n",
            "  1.27929688e-01  1.49414062e-01 -2.24609375e-02 -8.44726562e-02\n",
            "  1.22558594e-01  2.15820312e-01 -2.13867188e-01 -3.12500000e-01\n",
            " -3.73046875e-01  4.08935547e-03  1.07421875e-01  1.06933594e-01\n",
            "  7.32421875e-02  8.97216797e-03 -3.88183594e-02 -1.29882812e-01\n",
            "  1.49414062e-01 -2.14843750e-01 -1.83868408e-03  9.91210938e-02\n",
            "  1.57226562e-01 -1.14257812e-01 -2.05078125e-01  9.91210938e-02\n",
            "  3.69140625e-01 -1.97265625e-01  3.54003906e-02  1.09375000e-01\n",
            "  1.31835938e-01  1.66992188e-01  2.35351562e-01  1.04980469e-01\n",
            " -4.96093750e-01 -1.64062500e-01 -1.56250000e-01 -5.22460938e-02\n",
            "  1.03027344e-01  2.43164062e-01 -1.88476562e-01  5.07812500e-02\n",
            " -9.37500000e-02 -6.68945312e-02  2.27050781e-02  7.61718750e-02\n",
            "  2.89062500e-01  3.10546875e-01 -5.37109375e-02  2.28515625e-01\n",
            "  2.51464844e-02  6.78710938e-02 -1.21093750e-01 -2.15820312e-01\n",
            " -2.73437500e-01 -3.07617188e-02 -3.37890625e-01  1.53320312e-01\n",
            "  2.33398438e-01 -2.08007812e-01  3.73046875e-01  8.20312500e-02\n",
            "  2.51953125e-01 -7.61718750e-02 -4.66308594e-02 -2.23388672e-02\n",
            "  2.99072266e-02 -5.93261719e-02 -4.66918945e-03 -2.44140625e-01\n",
            " -2.09960938e-01 -2.87109375e-01 -4.54101562e-02 -1.77734375e-01\n",
            " -2.79296875e-01 -8.59375000e-02  9.13085938e-02  2.51953125e-01]\n",
            "\n",
            "Odd one out in the set ['man', 'woman', 'king', 'apple']: apple\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "odd_one_out = model.doesnt_match([\"cpp\", \"java\", \"dance\", \"javascript\"])"
      ],
      "metadata": {
        "id": "2e2xYjb2JLBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(odd_one_out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wf8TWIwEJQrC",
        "outputId": "8927a63f-175a-4730-95c4-2a0826228dca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dance\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_vector = model['apple']\n",
        "print(word_vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwXQjjKJJBKJ",
        "outputId": "25bbd441-4301-4665-f3be-6f65fc5b9b36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.06445312 -0.16015625 -0.01208496  0.13476562 -0.22949219  0.16210938\n",
            "  0.3046875  -0.1796875  -0.12109375  0.25390625 -0.01428223 -0.06396484\n",
            " -0.08056641 -0.05688477 -0.19628906  0.2890625  -0.05151367  0.14257812\n",
            " -0.10498047 -0.04736328 -0.34765625  0.35742188  0.265625    0.00188446\n",
            " -0.01586914  0.00195312 -0.35546875  0.22167969  0.05761719  0.15917969\n",
            "  0.08691406 -0.0267334  -0.04785156  0.23925781 -0.05981445  0.0378418\n",
            "  0.17382812 -0.41796875  0.2890625   0.32617188  0.02429199 -0.01647949\n",
            " -0.06494141 -0.08886719  0.07666016 -0.15136719  0.05249023 -0.04199219\n",
            " -0.05419922  0.00108337 -0.20117188  0.12304688  0.09228516  0.10449219\n",
            " -0.00408936 -0.04199219  0.01409912 -0.02111816 -0.13476562 -0.24316406\n",
            "  0.16015625 -0.06689453 -0.08984375 -0.07177734 -0.00595093 -0.00482178\n",
            " -0.00089264 -0.30664062 -0.0625      0.07958984 -0.00909424 -0.04492188\n",
            "  0.09960938 -0.33398438 -0.3984375   0.05541992 -0.06689453 -0.04467773\n",
            "  0.11767578 -0.13964844 -0.26367188  0.17480469 -0.17382812 -0.40625\n",
            " -0.06738281 -0.07617188  0.09423828  0.20996094 -0.16308594 -0.08691406\n",
            " -0.0534668  -0.10351562 -0.07617188 -0.11083984 -0.03515625 -0.14941406\n",
            "  0.0378418   0.38671875  0.14160156 -0.2890625  -0.16894531 -0.140625\n",
            " -0.04174805  0.22753906  0.24023438 -0.01599121 -0.06787109  0.21875\n",
            " -0.42382812 -0.5625     -0.49414062 -0.3359375   0.13378906  0.01141357\n",
            "  0.13671875  0.0324707   0.06835938 -0.27539062 -0.15917969  0.00121307\n",
            "  0.01208496 -0.0039978   0.00442505 -0.04541016  0.08642578  0.09960938\n",
            " -0.04296875 -0.11328125  0.13867188  0.41796875 -0.28320312 -0.07373047\n",
            " -0.11425781  0.08691406 -0.02148438  0.328125   -0.07373047 -0.01348877\n",
            "  0.17773438 -0.02624512  0.13378906 -0.11132812 -0.12792969 -0.12792969\n",
            "  0.18945312 -0.13867188  0.29882812 -0.07714844 -0.37695312 -0.10351562\n",
            "  0.16992188 -0.10742188 -0.29882812  0.00866699 -0.27734375 -0.20996094\n",
            " -0.1796875  -0.19628906 -0.22167969  0.08886719 -0.27734375 -0.13964844\n",
            "  0.15917969  0.03637695  0.03320312 -0.08105469  0.25390625 -0.08691406\n",
            " -0.21289062 -0.18945312 -0.22363281  0.06542969 -0.16601562  0.08837891\n",
            " -0.359375   -0.09863281  0.35546875 -0.00741577  0.19042969  0.16992188\n",
            " -0.06005859 -0.20605469  0.08105469  0.12988281 -0.01135254  0.33203125\n",
            " -0.08691406  0.27539062 -0.03271484  0.12011719 -0.0625      0.1953125\n",
            " -0.10986328 -0.11767578  0.20996094  0.19921875  0.02954102 -0.16015625\n",
            "  0.00276184 -0.01367188  0.03442383 -0.19335938  0.00352478 -0.06542969\n",
            " -0.05566406  0.09423828  0.29296875  0.04052734 -0.09326172 -0.10107422\n",
            " -0.27539062  0.04394531 -0.07275391  0.13867188  0.02380371  0.13085938\n",
            "  0.00236511 -0.2265625   0.34765625  0.13574219  0.05224609  0.18164062\n",
            "  0.0402832   0.23730469 -0.16992188  0.10058594  0.03833008  0.10839844\n",
            " -0.05615234 -0.00946045  0.14550781 -0.30078125 -0.32226562  0.18847656\n",
            " -0.40234375 -0.3125     -0.08007812 -0.26757812  0.16699219  0.07324219\n",
            "  0.06347656  0.06591797  0.17285156 -0.17773438  0.00276184 -0.05761719\n",
            " -0.2265625  -0.19628906  0.09667969  0.13769531 -0.49414062 -0.27929688\n",
            "  0.12304688 -0.30078125  0.01293945 -0.1875     -0.20898438 -0.1796875\n",
            " -0.16015625 -0.03295898  0.00976562  0.25390625 -0.25195312  0.00210571\n",
            "  0.04296875  0.01184082 -0.20605469  0.24804688 -0.203125   -0.17773438\n",
            "  0.07275391  0.04541016  0.21679688 -0.2109375   0.14550781 -0.16210938\n",
            "  0.20410156 -0.19628906 -0.35742188  0.35742188 -0.11962891  0.35742188\n",
            "  0.10351562  0.07080078 -0.24707031 -0.10449219 -0.19238281  0.1484375\n",
            "  0.00057983  0.296875   -0.12695312 -0.03979492  0.13183594 -0.16601562\n",
            "  0.125       0.05126953 -0.14941406  0.13671875 -0.02075195  0.34375   ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_vector.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DdKJ_ABH-GB",
        "outputId": "8ced514b-391e-488f-8e88-6c44e0966859"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(300,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How to use this pretrained word2vec model in the keras and tensorflow"
      ],
      "metadata": {
        "id": "_YsoGJzuIazE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling1D\n",
        "\n",
        "embedding_dim = 300  # Google Word2Vec model has 300 dimensions\n",
        "vocab_size = len(word2vec_model.key_to_index)  # Total number of words in vocabulary\n",
        "\n",
        "# Initialize embedding matrix with zeros\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "\n",
        "# Create a mapping from words to their corresponding vectors\n",
        "word_index = {}  # This will store {word: index} mapping\n",
        "\n",
        "for i, word in enumerate(word2vec_model.key_to_index.keys()):\n",
        "    embedding_matrix[i] = word2vec_model[word]\n",
        "    word_index[word] = i  # Assign index to each word\n",
        "\n",
        "print(\"Embedding matrix created!\")\n",
        "\n",
        "\n",
        "embedding_layer = tf.keras.layers.Embedding(\n",
        "    input_dim=vocab_size,    # Size of vocabulary\n",
        "    output_dim=embedding_dim,  # Word vector dimensions (300)\n",
        "    weights=[embedding_matrix],  # Load pretrained Word2Vec weights\n",
        "    input_length=20,  # Length of input sequences (adjust as needed)\n",
        "    trainable=False  # Set to False to freeze the pretrained embeddings\n",
        ")\n",
        "\n",
        "print(\"Embedding layer created!\")\n",
        "\n",
        "\n",
        "# Define a simple model\n",
        "model = Sequential([\n",
        "    embedding_layer,  # Pretrained Word2Vec embeddings\n",
        "    GlobalAveragePooling1D(),  # Averages word vectors\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "0gKLS8OsIfCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we can also use this to get the embedding matrix"
      ],
      "metadata": {
        "id": "VGGLErm4Jc-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the full weight matrix (each row corresponds to a word vector)\n",
        "import numpy as np\n",
        "\n",
        "embedding_weights = model.vectors\n",
        "\n",
        "print(\"Shape of embedding matrix:\", embedding_weights.shape)\n",
        "print(embedding_weights.dtype)\n",
        "\n",
        "\n",
        "# Convert the entire weight matrix to NumPy(copy of the above weights so we dont modify the original ones)\n",
        "embedding_matrix = np.array(embedding_weights)\n",
        "\n",
        "print(\"Embedding matrix shape:\", embedding_matrix.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SayQu0GNJfra",
        "outputId": "8afc807c-caf0-493e-b56d-c984299c8805"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of embedding matrix: (3000000, 300)\n",
            "float32\n",
            "Embedding matrix shape: (3000000, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eE1uj9oHveUH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}